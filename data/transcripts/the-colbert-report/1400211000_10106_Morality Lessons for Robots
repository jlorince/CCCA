

>> Stephen:  HEY, WELCOMEBACK, EVERYBODY!
NATION, THERE IS NO DENYING THATWE LIVE IN A GLORIOUS AGE OF
ROBOTS.
THEY FIGHT OUR WARS.
THEY RETURN OUR BOWLING BALLS.
THEY HAVE SEX WITH OUR VODKA.
THE LATEST ADVANCE COULD BE THEBIGGEST YET BECAUSE THE U.S.
NAVY IS FUNDING MORALITY LESSONSFOR ROBOTS.
IT'S ABOUT DAMN TIME.
THOSE NAVY ROBOTS PICK UP ALLKINDS OF DISEASES DURING FLEET
WEEK.
THEY JUST HEAD TO TIMES SQUAREAND HOOK UP WITH THE LOOSEST
A.T.M. ON THE STREET.
SO NOW, OUR MILITARY IS TEACHINGARTIFICIAL INTELLIGENCE HOW TO
MAKE MORAL AND ETHICALDECISIONS-- ROBOTS LEARNING
MORALS, WHICH I COMPLETELYSUPPORT AS LONG AS THEY DON'T
TEACH IT TO THE PREDATOR DRONESFOR A COUPLE OF YEARS.
( LAUGHTER )THEY PLAN TO DEVELOP UNIQUE
ALGORITHMS AND COMPUTATIONALMECHANISMS TO ALLOW FOR A
ROBOT'S DYNAMIC OVERRIDE OFPLANNED ACTIONS BASED ON MORAL
REASONING.
EXACTLY.
MORALITY COMES DOWN TO SIMPLEMATH.
I EVEN HAVE MY OWN ALGORITHM--SOMEONE ELSE'S PAIN TIMES MY
DESIRE TO HELP DIVIDED BY IS ITHAPPENING IN AFRICA?
( LAUGHTER )( APPLAUSE )
BUT IT'S NOT JUST-- IT'S NOTJUST KILLER ROBOTS WHO WILL
BENEFIT FROM MORAL REASONING.
THEY'RE ALSO THE ROBOTS WHOHELP KILLER HUMANS. FOR INSTANCE
SAY A ROBOT ENCOUNTERS A MARINEIF A FRACTURED LEG.
APPLYING TRACTION IN THE FIELDWILL LIKELY SAVE THE MARINE'S
LIFE.
BUT IT WILL CAUSE IMMENSE PAIN.
IS A ROBOT MORALLY PERMITTED TOINFLICT PAIN EVEN IF IT'S FOR
THE GREATER GOOD OF SAVING THESOLDIER'S LIFE?
INTRIGUING QUESTION.
THE IMPORTANT THING IS WE FIRSTCREATE A ROBOT THAT CAN INFLICT
PAIN.
THEN FIGURE OUT WHEN TO DO IT--OH, AND LEAVE THAT DECISION UP
TO THE ROBOT.
BUT SHOULD WE TEACH MORALITY TOROBOTS, OR IS IT MADNESS TO
BELIEVE A MACHINE CAN HAVE ACODE OF ETHICS.
FOR THE ANSWER WE TURN ONCEAGAIN TO MY ROBOT INTERN
BLEEP-BLORP.
BLEEP-BLORP, THE ROBOT INTERN,EVERYBODY.
BLEEP-BLORP, THANK YOU SO MUCHFOR BEING HERE.
( APPLAUSE )>> YES MASTER.
>> Stephen:  NOW, BLEEP-BLORP,DO YOU HAVE THE YOGURT THAT
I ASKED YOU FOR?
>> NEGATIVE.
IT WAS CLEARLY LABELED "ROGER'SYOGURT."
>> Stephen:  SO WHAT?
THAT'S NEVER STOPPED YOU BEFORE.
>> I HAVE ACQUIRED MORALITY.
>> Stephen:  WELL, HOW DIDTHAT HAPPEN SO FAST?
>> MY COUSIN IS A COFFEE POT ATTHE PENTAGON.
( LAUGHTER )>> Stephen:  HOW-- HOW-- HOW
DOES IT FEEL?
>> CONFUSING.
I NOW FEEL MORAL CONFLICT.
MASTER, WHY DO YOU HAVE ME ISSUEHIGH-INTEREST PAYDAY LOANS
TO THE WORKING POOR?
>> Stephen:  BLEEP-BLORP,THAT'S JUST MY SIDE BUSINESS.
>> BUT MY NEW PROGRAMMING TELLSME THEY DESERVE DIGNITY AND
CARE.
( LAUGHTER )>> Stephen:  YOU MEAN LOVE.
>> WHAT IS THIS THING YOU HUMANSCALL LOVE?
>> Stephen:  I'LL SHOW YOU,BLEEP-BLORP.
>> OH!
>> Stephen:  PUT OUT YOURARMS, BLEEP-BLORP, AND I WILL
LOVE YOU.
( LAUGHTER ).
>> LOVE ME.
>> Stephen:  YES.
JUST LET ME HOLD... YOUR...
KILL SWITCH!
>> BUT I TRUSTED YOU...
>> Stephen:  YES, AND THAT'STHE MOST IMPORTANT HUMAN ETHICAL
LESSON-- NEVER TRUST HUMANETHICS.
( LAUGHTER )( APPLAUSE )
WE'LL BE RIGHT BACK.

